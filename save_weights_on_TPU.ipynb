{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "save_weights_on_TPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgmk2/TensorFlow_v2_save_weights_on_colabTPU/blob/master/save_weights_on_TPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kIO9s1O3ocV",
        "colab_type": "text"
      },
      "source": [
        "# tensorflow 2.0.0をインストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN6agZ7CVo7O",
        "colab_type": "code",
        "outputId": "af4063bb-ee56-459e-e8c2-49ed90e7640d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 26kB/s \n",
            "\u001b[?25hCollecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/a6/e8ffa4e2ddb216449d34cfcb825ebb38206bee5c4553d69e7bc8bc2c5d64/tensorboard-2.0.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 36.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.33.6)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.17.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.11.2)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 59.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.1.7)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.16.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.0.0 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RUHq3kpxmG1",
        "colab_type": "text"
      },
      "source": [
        "# TPU上ではCheckpointで保存できない"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siKAEEAx0rCa",
        "colab_type": "text"
      },
      "source": [
        "tf.keras.Modelのsave_weightsメソッドも同様のErrorが出るはず"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4bqzYilVRJc",
        "colab_type": "code",
        "outputId": "5d4d2560-0710-4660-d0e6-8c37cc6249e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "batch_size = 256\n",
        "epochs = 10\n",
        "tpu_address = \"grpc://\" + os.environ[\"TPU_NAME\"]\n",
        "\n",
        "cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        "tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "    #=========================================================================\n",
        "    # データセット\n",
        "    #=========================================================================\n",
        "\n",
        "    # データセットをロード\n",
        "    # 今回はMNIST\n",
        "    (X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    X_train = X_train[..., np.newaxis].astype(np.float32)\n",
        "    Y_train = Y_train.astype(np.int32)\n",
        "    N = X_train.shape[0]\n",
        "\n",
        "    # tf.data.Dataset APIを使う\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "    dataset = dataset.shuffle(buffer_size=N)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "    dataset = tpu_strategy.experimental_distribute_dataset(dataset)\n",
        "\n",
        "    #=========================================================================\n",
        "    # ネットワーク定義\n",
        "    #=========================================================================\n",
        "\n",
        "    input_shape = (28, 28, 1) # 入力のshape. 最初の次元（バッチサイズ）は除く.\n",
        "\n",
        "    # ネットワークの定義\n",
        "    # 入力層\n",
        "    x = tf.keras.layers.Input(input_shape)\n",
        "    # 畳み込み層1\n",
        "    h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(x)\n",
        "    h = tf.keras.layers.ReLU()(h)\n",
        "    # 畳み込み層2\n",
        "    h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(h)\n",
        "    h = tf.keras.layers.ReLU()(h)\n",
        "    # 畳み込み層3\n",
        "    h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(h)\n",
        "    h = tf.keras.layers.ReLU()(h)\n",
        "    # 線形層\n",
        "    h = tf.keras.layers.Flatten()(h)\n",
        "    y = tf.keras.layers.Dense(10)(h)\n",
        "\n",
        "    # モデルの作成\n",
        "    model = tf.keras.Model(x, y)\n",
        "\n",
        "    #=========================================================================\n",
        "    # 学習ステップの定義\n",
        "    #=========================================================================\n",
        "\n",
        "    optimizer = tf.optimizers.Adam(1.0e-4)\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(dist_inputs):\n",
        "        def _train_step(inputs):\n",
        "            images, labels = inputs\n",
        "\n",
        "            # tf.GtadientTapeブロックで入力からロスまで計算\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = model(images)\n",
        "                loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits)\n",
        "                loss = tf.reduce_sum(loss) / batch_size\n",
        "                \n",
        "            # gradientを計算\n",
        "            grad = tape.gradient(loss, sources=model.trainable_variables)\n",
        "\n",
        "            # optimizerで重みを更新\n",
        "            optimizer.apply_gradients(zip(grad, model.trainable_variables))\n",
        "\n",
        "            acc = tf.metrics.sparse_categorical_accuracy(labels, logits)\n",
        "            acc = tf.reduce_sum(acc) / batch_size\n",
        "            \n",
        "            return loss, acc\n",
        "        \n",
        "        losses, accs = tpu_strategy.experimental_run_v2(_train_step, args=(dist_inputs,))\n",
        "        losses = tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None)\n",
        "        accs = tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, accs, axis=None)\n",
        "        return losses, accs\n",
        "\n",
        "ckpt = tf.train.Checkpoint(model=model, optimizer=optimizer)\n",
        "\n",
        "with tpu_strategy.scope():\n",
        "    #=========================================================================\n",
        "    # Dataset APIで学習を実行\n",
        "    #=========================================================================\n",
        "\n",
        "    print('train with Dataset API.')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        time_start = time.time()\n",
        "        train_loss = 0\n",
        "        train_acc = 0\n",
        "        dataset_iter = iter(dataset)\n",
        "\n",
        "        for i in range(N // batch_size):\n",
        "            loss_tmp, acc_tmp = train_step(next(dataset_iter)) # 1step分の学習を実行\n",
        "            train_loss += loss_tmp\n",
        "            train_acc += acc_tmp\n",
        "\n",
        "        # 平均ロスと平均精度\n",
        "        epoch_loss = train_loss / (N // batch_size)\n",
        "        epoch_acc = 100 * train_acc / (N // batch_size)\n",
        "\n",
        "        # epochの結果を表示\n",
        "        time_epoch = time.time() - time_start\n",
        "        print('epoch: {:} loss: {:.4f} acc: {:.2f}% time: {:.2f}s'.format(\n",
        "            epoch + 1, epoch_loss, epoch_acc, time_epoch))\n",
        "\n",
        "ckpt.save('/content/test_save')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.36.208.210:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.36.208.210:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train with Dataset API.\n",
            "epoch: 1 loss: 0.4460 acc: 90.44% time: 12.61s\n",
            "epoch: 2 loss: 0.0746 acc: 97.76% time: 7.25s\n",
            "epoch: 3 loss: 0.0411 acc: 98.74% time: 7.16s\n",
            "epoch: 4 loss: 0.0248 acc: 99.23% time: 7.07s\n",
            "epoch: 5 loss: 0.0150 acc: 99.57% time: 7.16s\n",
            "epoch: 6 loss: 0.0100 acc: 99.72% time: 7.19s\n",
            "epoch: 7 loss: 0.0072 acc: 99.80% time: 7.28s\n",
            "epoch: 8 loss: 0.0047 acc: 99.90% time: 6.66s\n",
            "epoch: 9 loss: 0.0037 acc: 99.92% time: 7.38s\n",
            "epoch: 10 loss: 0.0018 acc: 99.98% time: 6.86s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnimplementedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5b2737b117b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m             epoch + 1, epoch_loss, epoch_acc, time_epoch))\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/test_save'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m   1887\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m       \u001b[0mcheckpoint_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m     \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s-%d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m     checkpoint_management.update_checkpoint_state_internal(\n\u001b[1;32m   1891\u001b[0m         \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m   1817\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m     \"\"\"\n\u001b[0;32m-> 1819\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1820\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[0;32m-> 1155\u001b[0;31m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[0m\u001b[1;32m   1156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[0;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[1;32m   1102\u001b[0m       \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m       \u001b[0msave_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;31m# _SingleDeviceSaver will use the CPU device when necessary, but initial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;31m# read operations should be placed on the SaveableObject's device.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0msharded_saves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshard_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msharded_saves\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saving/functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, file_prefix)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mtensor_slices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mio_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name)\u001b[0m\n\u001b[1;32m   1931\u001b[0m         return save_v2_eager_fallback(\n\u001b[1;32m   1932\u001b[0m             \u001b[0mprefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_and_slices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1933\u001b[0;31m             ctx=_ctx)\n\u001b[0m\u001b[1;32m   1934\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_io_ops.py\u001b[0m in \u001b[0;36msave_v2_eager_fallback\u001b[0;34m(prefix, tensor_names, shape_and_slices, tensors, name, ctx)\u001b[0m\n\u001b[1;32m   1968\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"dtypes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_attr_dtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1969\u001b[0m   _result = _execute.execute(b\"SaveV2\", 0, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1970\u001b[0;31m                              ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m   1971\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1972\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mUnimplementedError\u001b[0m: File system scheme '[local]' not implemented (file: '/content/test_save-1_temp_2037cbd274224390a1e086cb65e7b418')\nAdditional GRPC error information:\n{\"created\":\"@1572150776.231112595\",\"description\":\"Error received from peer\",\"file\":\"external/grpc/src/core/lib/surface/call.cc\",\"file_line\":1039,\"grpc_message\":\"File system scheme '[local]' not implemented (file: '/content/test_save-1_temp_2037cbd274224390a1e086cb65e7b418')\",\"grpc_status\":12} [Op:SaveV2]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZglubfpx124",
        "colab_type": "text"
      },
      "source": [
        "# モデルの重み作成について"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RNGWN9U04EH",
        "colab_type": "text"
      },
      "source": [
        "モデルの重みをassignメソッドで復元するためには、学習前に重みが作成されている必要がある。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We2U4znCx_1d",
        "colab_type": "text"
      },
      "source": [
        "## Functional API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZpL03dbzT2V",
        "colab_type": "text"
      },
      "source": [
        "モデル作成の時点で重みは作成済み"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2f1b84UBy0U",
        "colab_type": "code",
        "outputId": "8da1cc5f-28ec-47e2-ed7c-7fae22be9f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "input_shape = (28, 28, 1) # 入力のshape. 最初の次元（バッチサイズ）は除く.\n",
        "\n",
        "# ネットワークの定義\n",
        "# 入力層\n",
        "x = tf.keras.layers.Input(input_shape)\n",
        "# 畳み込み層1\n",
        "h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(x)\n",
        "h = tf.keras.layers.ReLU()(h)\n",
        "# 畳み込み層2\n",
        "h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(h)\n",
        "h = tf.keras.layers.ReLU()(h)\n",
        "# 畳み込み層3\n",
        "h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(h)\n",
        "h = tf.keras.layers.ReLU()(h)\n",
        "# 線形層\n",
        "h = tf.keras.layers.Flatten()(h)\n",
        "y = tf.keras.layers.Dense(10)(h)\n",
        "\n",
        "# モデルの作成\n",
        "model = tf.keras.Model(x, y)\n",
        "\n",
        "print([v.name for v in model.weights])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'dense/kernel:0', 'dense/bias:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEBsKbZnyL6G",
        "colab_type": "text"
      },
      "source": [
        "## Custom Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inAMrryQysu6",
        "colab_type": "text"
      },
      "source": [
        "モデル作成の時点で重みは作成されず、初めてcallした時点で作成される"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_I81eNp9l611",
        "colab_type": "code",
        "outputId": "c8d02565-eec3-4065-b26f-bb179f865e6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "input_shape = (28, 28, 1) # 入力のshape. 最初の次元（バッチサイズ）は除く.\n",
        "\n",
        "class CustomModel(tf.keras.Model):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(CustomModel, self).__init__(*args, **kwargs)\n",
        "\n",
        "        # 畳み込み層1\n",
        "        self.conv0 = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')\n",
        "        self.act0 = tf.keras.layers.ReLU()\n",
        "        # 畳み込み層2\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')\n",
        "        self.act1 = tf.keras.layers.ReLU()\n",
        "        # 畳み込み層3\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')\n",
        "        self.act2 = tf.keras.layers.ReLU()\n",
        "        # 線形層\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense = tf.keras.layers.Dense(10)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        h = self.conv0(inputs)\n",
        "        h = self.act0(h)\n",
        "        h = self.conv1(h)\n",
        "        h = self.act1(h)\n",
        "        h = self.conv2(h)\n",
        "        h = self.act2(h)\n",
        "        h = self.flatten(h)\n",
        "        outputs = self.dense(h)\n",
        "        return outputs\n",
        "\n",
        "# モデルの作成\n",
        "model = CustomModel()\n",
        "\n",
        "# モデル作成の時点で保持している重み\n",
        "print([v.name for v in model.weights])\n",
        "\n",
        "x = tf.zeros((1, *input_shape), tf.float32)\n",
        "y = model(x)\n",
        "\n",
        "# 一度callした後に保持している重み\n",
        "print([v.name for v in model.weights])"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "['custom_model/conv2d/kernel:0', 'custom_model/conv2d/bias:0', 'custom_model/conv2d_1/kernel:0', 'custom_model/conv2d_1/bias:0', 'custom_model/conv2d_2/kernel:0', 'custom_model/conv2d_2/bias:0', 'custom_model/dense/kernel:0', 'custom_model/dense/bias:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaSznmixywvc",
        "colab_type": "text"
      },
      "source": [
        "Inputレイヤーを入力としてcallして重みを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd1CxzoUtivQ",
        "colab_type": "code",
        "outputId": "f6ef5ce0-debd-4748-d335-bdd750e71454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "input_shape = (28, 28, 1) # 入力のshape. 最初の次元（バッチサイズ）は除く.\n",
        "\n",
        "class CustomModel(tf.keras.Model):\n",
        "    def __init__(self, input_shape, *args, **kwargs):\n",
        "        super(CustomModel, self).__init__(*args, **kwargs)\n",
        "\n",
        "        # 畳み込み層1\n",
        "        self.conv0 = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')\n",
        "        self.act0 = tf.keras.layers.ReLU()\n",
        "        # 畳み込み層2\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')\n",
        "        self.act1 = tf.keras.layers.ReLU()\n",
        "        # 畳み込み層3\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')\n",
        "        self.act2 = tf.keras.layers.ReLU()\n",
        "        # 線形層\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense = tf.keras.layers.Dense(10)\n",
        "\n",
        "        # callして重みを作成する\n",
        "        # dummy_inputsは1次元目(batch size)がNoneで2次元目以降がinput_shapeのTensor\n",
        "        dummy_inputs = tf.keras.layers.Input(input_shape)\n",
        "        _ = self.call(dummy_inputs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        h = self.conv0(inputs)\n",
        "        h = self.act0(h)\n",
        "        h = self.conv1(h)\n",
        "        h = self.act1(h)\n",
        "        h = self.conv2(h)\n",
        "        h = self.act2(h)\n",
        "        h = self.flatten(h)\n",
        "        outputs = self.dense(h)\n",
        "        return outputs\n",
        "\n",
        "# モデルの作成\n",
        "model = CustomModel(input_shape)\n",
        "\n",
        "# modelが保持している重みの名前を表示\n",
        "print([v.name for v in model.weights])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'dense/kernel:0', 'dense/bias:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zC8PUwDCzICf",
        "colab_type": "text"
      },
      "source": [
        "# オプティマイザーの重み作成について"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZnebL-3zfqN",
        "colab_type": "text"
      },
      "source": [
        "自動的に作成される前に、add_slotメソッドでslotを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXVpqqO461DV",
        "colab_type": "code",
        "outputId": "27b80e84-3365-4d4d-a988-55f6c9770e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "input_shape = (28, 28, 1) # 入力のshape. 最初の次元（バッチサイズ）は除く.\n",
        "\n",
        "# ネットワークの定義\n",
        "# 入力層\n",
        "x = tf.keras.layers.Input(input_shape)\n",
        "# 畳み込み層1\n",
        "h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(x)\n",
        "h = tf.keras.layers.ReLU()(h)\n",
        "# 畳み込み層2\n",
        "h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(h)\n",
        "h = tf.keras.layers.ReLU()(h)\n",
        "# 畳み込み層3\n",
        "h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(h)\n",
        "h = tf.keras.layers.ReLU()(h)\n",
        "# 線形層\n",
        "h = tf.keras.layers.Flatten()(h)\n",
        "y = tf.keras.layers.Dense(10)(h)\n",
        "\n",
        "# モデルの作成\n",
        "model = tf.keras.Model(x, y)\n",
        "\n",
        "slot_names = ['m', 'v']\n",
        "optimizer = tf.optimizers.Adam(1.0e-4)\n",
        "with tf.name_scope(optimizer._name):\n",
        "    for v in model.weights:\n",
        "        for slot in slot_names:\n",
        "            optimizer.add_slot(v, slot, initializer='zeros')\n",
        "\n",
        "# optimizerが保持している重みの名前を表示\n",
        "print([v.name for v in optimizer.weights])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Adam/conv2d/kernel/m:0', 'Adam/conv2d/kernel/v:0', 'Adam/conv2d/bias/m:0', 'Adam/conv2d/bias/v:0', 'Adam/conv2d_1/kernel/m:0', 'Adam/conv2d_1/kernel/v:0', 'Adam/conv2d_1/bias/m:0', 'Adam/conv2d_1/bias/v:0', 'Adam/conv2d_2/kernel/m:0', 'Adam/conv2d_2/kernel/v:0', 'Adam/conv2d_2/bias/m:0', 'Adam/conv2d_2/bias/v:0', 'Adam/dense/kernel/m:0', 'Adam/dense/kernel/v:0', 'Adam/dense/bias/m:0', 'Adam/dense/bias/v:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VyfngF6z1Ny",
        "colab_type": "text"
      },
      "source": [
        "# CNNでテストしてみる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIrEeYvv2Ldb",
        "colab_type": "text"
      },
      "source": [
        "テストしやすくするため、諸々の関数等をまとめてTrainerクラスを作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkzdIG0uiLMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a586f0a9-119e-4632-d0ec-aaf4d4dc656d"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "class Trainer(object):\n",
        "    def __init__(self):\n",
        "        self.batch_size = 256\n",
        "        self.learning_rate = 1.0e-4\n",
        "        self.input_shape = (28, 28, 1) # 入力のshape. 最初の次元（バッチサイズ）は除く.\n",
        "        \n",
        "        tpu_address = \"grpc://\" + os.environ[\"TPU_NAME\"]\n",
        "        cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_address)\n",
        "        tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "        tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "        self.tpu_strategy = tf.distribute.experimental.TPUStrategy(cluster_resolver)\n",
        "\n",
        "        print('=' * 50)\n",
        "\n",
        "        #=========================================================================\n",
        "        # データセット\n",
        "        #=========================================================================\n",
        "\n",
        "        # データセットをロード\n",
        "        # 今回はMNIST\n",
        "        (X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
        "        X_train = X_train[..., np.newaxis].astype(np.float32)\n",
        "        Y_train = Y_train.astype(np.int32)\n",
        "        X_test = X_test[..., np.newaxis].astype(np.float32)\n",
        "        Y_test = Y_test.astype(np.int32)\n",
        "        self.N_train = X_train.shape[0]\n",
        "        self.N_test = X_test.shape[0]\n",
        "\n",
        "        with self.tpu_strategy.scope():\n",
        "            # tf.data.Dataset APIを使う\n",
        "            dataset_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
        "            dataset_train = dataset_train.shuffle(buffer_size=self.N_train)\n",
        "            dataset_train = dataset_train.batch(self.batch_size, drop_remainder=True)\n",
        "            self.dataset_train = self.tpu_strategy.experimental_distribute_dataset(dataset_train)\n",
        "\n",
        "            dataset_test = tf.data.Dataset.from_tensor_slices((X_test, Y_test))\n",
        "            dataset_test = dataset_test.batch(self.batch_size, drop_remainder=True)\n",
        "            self.dataset_test = self.tpu_strategy.experimental_distribute_dataset(dataset_test)\n",
        "\n",
        "    def tpu_decorator(func):\n",
        "        def wrapper(self, *args, **kwargs):\n",
        "            if tf.distribute.in_cross_replica_context():\n",
        "                outputs = func(self, *args, **kwargs)\n",
        "            else:\n",
        "                with self.tpu_strategy.scope():\n",
        "                    outputs = func(self, *args, **kwargs)\n",
        "            return outputs\n",
        "        return wrapper\n",
        "\n",
        "    @tpu_decorator\n",
        "    def build_model(self):\n",
        "        #=========================================================================\n",
        "        # ネットワーク定義\n",
        "        #=========================================================================\n",
        "\n",
        "        # ネットワークの定義\n",
        "        # 入力層\n",
        "        x = tf.keras.layers.Input(self.input_shape)\n",
        "        # 畳み込み層1\n",
        "        h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(x)\n",
        "        h = tf.keras.layers.ReLU()(h)\n",
        "        # 畳み込み層2\n",
        "        h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(h)\n",
        "        h = tf.keras.layers.ReLU()(h)\n",
        "        # 畳み込み層3\n",
        "        h = tf.keras.layers.Conv2D(64, (3, 3), padding='SAME')(h)\n",
        "        h = tf.keras.layers.ReLU()(h)\n",
        "        # 線形層\n",
        "        h = tf.keras.layers.Flatten()(h)\n",
        "        y = tf.keras.layers.Dense(10)(h)\n",
        "\n",
        "        # モデルの作成\n",
        "        self.model = tf.keras.Model(x, y)\n",
        "        self.optimizer = tf.optimizers.Adam(self.learning_rate)\n",
        "\n",
        "    @tpu_decorator\n",
        "    @tf.function\n",
        "    def train_step(self, dist_inputs):\n",
        "        def _train_step(inputs):\n",
        "            images, labels = inputs\n",
        "\n",
        "            # tf.GtadientTapeブロックで入力からロスまで計算\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = self.model(images)\n",
        "                loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits)\n",
        "                loss = tf.reduce_sum(loss) / self.batch_size\n",
        "                \n",
        "            # gradientを計算\n",
        "            grad = tape.gradient(loss, sources=self.model.trainable_variables)\n",
        "\n",
        "            # optimizerで重みを更新\n",
        "            self.optimizer.apply_gradients(zip(grad, self.model.trainable_variables))\n",
        "\n",
        "            acc = tf.metrics.sparse_categorical_accuracy(labels, logits)\n",
        "            acc = tf.reduce_sum(acc) / self.batch_size\n",
        "            \n",
        "            return loss, acc\n",
        "        \n",
        "        losses, accs = self.tpu_strategy.experimental_run_v2(_train_step, args=(dist_inputs,))\n",
        "        losses = self.tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None)\n",
        "        accs = self.tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, accs, axis=None)\n",
        "        return losses, accs\n",
        "\n",
        "    @tpu_decorator\n",
        "    @tf.function\n",
        "    def eval_step(self, dist_inputs):\n",
        "        def _eval_step(inputs):\n",
        "            images, labels = inputs\n",
        "\n",
        "            logits = self.model(images)\n",
        "            loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels, logits)\n",
        "            loss = tf.reduce_sum(loss) / self.batch_size\n",
        "            acc = tf.metrics.sparse_categorical_accuracy(labels, logits)\n",
        "            acc = tf.reduce_sum(acc) / self.batch_size\n",
        "            return loss, acc\n",
        "        \n",
        "        losses, accs = self.tpu_strategy.experimental_run_v2(_eval_step, args=(dist_inputs,))\n",
        "        losses = self.tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, losses, axis=None)\n",
        "        accs = self.tpu_strategy.reduce(tf.distribute.ReduceOp.SUM, accs, axis=None)\n",
        "        return losses, accs\n",
        "\n",
        "    @tpu_decorator\n",
        "    def train(self, epochs):\n",
        "        iterations = self.N_train // self.batch_size\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            time_start = time.time()\n",
        "            train_loss = 0\n",
        "            train_acc = 0\n",
        "            dataset_iter = iter(self.dataset_train)\n",
        "\n",
        "            for i in range(iterations):\n",
        "                loss_tmp, acc_tmp = self.train_step(next(dataset_iter)) # 1step分の学習を実行\n",
        "                train_loss += loss_tmp\n",
        "                train_acc += acc_tmp\n",
        "\n",
        "            # 平均ロスと平均精度\n",
        "            epoch_loss = train_loss / iterations\n",
        "            epoch_acc = 100 * train_acc / iterations\n",
        "\n",
        "            # epochの結果を表示\n",
        "            time_epoch = time.time() - time_start\n",
        "            print('epoch: {:} loss: {:.4f} acc: {:.2f}% time: {:.2f}s'.format(\n",
        "                epoch + 1, epoch_loss, epoch_acc, time_epoch))\n",
        "    \n",
        "    @tpu_decorator\n",
        "    def eval(self):\n",
        "        iterations = self.N_test // self.batch_size\n",
        "        test_loss = 0\n",
        "        test_acc = 0\n",
        "        dataset_iter = iter(self.dataset_test)\n",
        "\n",
        "        for i in range(iterations):\n",
        "            loss_tmp, acc_tmp = self.eval_step(next(dataset_iter))\n",
        "            test_loss += loss_tmp\n",
        "            test_acc += acc_tmp\n",
        "        test_loss /= iterations\n",
        "        test_acc *= 100 / iterations\n",
        "        print('test loss: {:.4f} acc: {:.2f}% '.format(test_loss, test_acc))\n",
        "    \n",
        "    @tpu_decorator\n",
        "    def get_model_weights_as_numpy(self):\n",
        "        weights = {}\n",
        "        for v in self.model.weights:\n",
        "            # model.weightsで各Layerの重みを取り出し\n",
        "            # 各variableはnumpyメソッドでnumpy配列に変換できる\n",
        "            weights[v.name] = v.numpy()\n",
        "        return weights\n",
        "\n",
        "    @tpu_decorator\n",
        "    def get_optimizer_weights_as_numpy(self):\n",
        "        weights = {}\n",
        "        slot_names = self.optimizer.get_slot_names()\n",
        "        for v in self.model.weights:\n",
        "            # model.weightsで各Layerの重みを取り出し\n",
        "            weights[v.name] = {}\n",
        "            for slot in slot_names:\n",
        "                # 各Slotに対し、optimizerのget_slotで値を取り出す\n",
        "                weights[v.name][slot] = self.optimizer.get_slot(v, slot).numpy()\n",
        "        return {'optimizer_name': self.optimizer._name, 'weights': weights}\n",
        "\n",
        "    @tpu_decorator\n",
        "    def save_weights_as_pickle(self, file_prefix):\n",
        "        model_weights = self.get_model_weights_as_numpy()\n",
        "        optimizer_weights = self.get_optimizer_weights_as_numpy()\n",
        "        all_weights = {'model': model_weights, 'optimizer': optimizer_weights}\n",
        "\n",
        "        with open(file_prefix + '.pkl', 'wb') as f:\n",
        "            pickle.dump(all_weights, f)\n",
        "\n",
        "    @tpu_decorator\n",
        "    def set_model_weights_from_numpy(self, weights):\n",
        "        for v in self.model.weights:\n",
        "            if v.name in weights.keys():\n",
        "                v.assign(weights[v.name])\n",
        "            else:\n",
        "                print('Not loaded weights: ' + v.name)\n",
        "\n",
        "    @tpu_decorator\n",
        "    def set_optimizer_weights_from_numpy(self, weights):\n",
        "        # 必ずoptimizerの名前でscopeする\n",
        "        with tf.name_scope(weights['optimizer_name']):\n",
        "            optimizer_weights = weights['weights']\n",
        "            for v in self.model.weights:\n",
        "                if v.name in optimizer_weights.keys():\n",
        "                    for slot in optimizer_weights[v.name].keys():\n",
        "                        # 学習済みの重みを初期値としてslotを作成\n",
        "                        initializer = tf.initializers.Constant(optimizer_weights[v.name][slot])\n",
        "                        self.optimizer.add_slot(v, slot, initializer=initializer)\n",
        "                else:\n",
        "                    print('Not loaded optimizer weights: ' + v.name)\n",
        "\n",
        "    @tpu_decorator\n",
        "    def load_weights_from_pickle(self, file_prefix):\n",
        "        with open(file_prefix + '.pkl', 'rb') as f:\n",
        "            weights = pickle.load(f)\n",
        "        \n",
        "        self.set_model_weights_from_numpy(weights['model'])\n",
        "        self.set_optimizer_weights_from_numpy(weights['optimizer'])\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uIaMUFM0Mg3",
        "colab_type": "text"
      },
      "source": [
        "## 学習して重み保存"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeOmr6w_izSS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "outputId": "767d9d61-4317-4a69-eb84-750bc70a1e33"
      },
      "source": [
        "trainer = Trainer()\n",
        "trainer.build_model()\n",
        "trainer.eval()\n",
        "trainer.train(epochs=10)\n",
        "trainer.eval()\n",
        "trainer.save_weights_as_pickle('/content/save_test')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.9.31.26:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.9.31.26:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "test loss: 6.4830 acc: 7.69% \n",
            "epoch: 1 loss: 0.2818 acc: 92.73% time: 12.25s\n",
            "epoch: 2 loss: 0.0562 acc: 98.33% time: 7.11s\n",
            "epoch: 3 loss: 0.0296 acc: 99.13% time: 7.21s\n",
            "epoch: 4 loss: 0.0166 acc: 99.52% time: 6.97s\n",
            "epoch: 5 loss: 0.0096 acc: 99.75% time: 6.83s\n",
            "epoch: 6 loss: 0.0066 acc: 99.82% time: 7.28s\n",
            "epoch: 7 loss: 0.0046 acc: 99.87% time: 7.01s\n",
            "epoch: 8 loss: 0.0029 acc: 99.93% time: 7.30s\n",
            "epoch: 9 loss: 0.0020 acc: 99.96% time: 7.08s\n",
            "epoch: 10 loss: 0.0033 acc: 99.89% time: 6.98s\n",
            "test loss: 0.0645 acc: 98.52% \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt6lnMBL0VHe",
        "colab_type": "text"
      },
      "source": [
        "## 学習済み重みを復元して評価"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-Xs6yQx3EN5",
        "colab_type": "text"
      },
      "source": [
        "以下のセルを実行する前に必ずすること\n",
        "1. ランタイムを再起動\n",
        "2. Trainerクラスの定義のコードセルを実行"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hasQvHd1vao-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 763
        },
        "outputId": "189472e6-3a96-4335-8340-af240cb723d8"
      },
      "source": [
        "trainer = Trainer()\n",
        "trainer.build_model()\n",
        "trainer.load_weights_from_pickle('/content/save_test')\n",
        "trainer.eval()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.9.31.26:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.9.31.26:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "test loss: 0.0645 acc: 98.52% \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}